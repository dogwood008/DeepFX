{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Python] Keras-RLで簡単に強化学習(DQN)を試す](http://qiita.com/inoory/items/e63ade6f21766c7c2393)を参考に、エージェントを作成する。FXの自動取引を行い、利益を出すのが目標。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import gym.spaces\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import enum\n",
    "from logging import getLogger, StreamHandler, DEBUG, INFO\n",
    "import time\n",
    "import keras\n",
    "import os\n",
    "import warnings\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6,
     12
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = getLogger(__name__)\n",
    "handler = StreamHandler()\n",
    "handler.setLevel(INFO)\n",
    "logger.setLevel(INFO)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "class DebugTools:\n",
    "    def now():\n",
    "        return dt.datetime.now() + dt.timedelta(hours=9)\n",
    "    def now_str():    \n",
    "        return DebugTools.now().strftime('%y/%m/%d %H:%M:%S')\n",
    "\n",
    "class Action(enum.Enum):\n",
    "    SELL = -1; STAY = 0; BUY = +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HistData:\n",
    "    def __init__(self, date_range=None):\n",
    "        self.csv_path = 'historical_data/USDJPY.hst_.csv'\n",
    "        self.csv_data = pd.read_csv(self.csv_path, index_col=0, parse_dates=True, header=0)\n",
    "        self.date_range = date_range\n",
    "        \n",
    "    def set_date_range(self, date_range):\n",
    "        self.date_range = date_range\n",
    "\n",
    "    def data(self):\n",
    "        if self.date_range is None:\n",
    "            return self.csv_data\n",
    "        else:\n",
    "            return self.csv_data[self.date_range]\n",
    "\n",
    "    def max_value(self):\n",
    "        return self.data()[['High']].max()['High']\n",
    "\n",
    "    def min_value(self):\n",
    "        return self.data()[['Low']].min()['Low']\n",
    "\n",
    "    def dates(self):\n",
    "        return self.data().index.values\n",
    "\n",
    "    ''' 引数の日時がデータフレームに含まれるか '''\n",
    "    def has_datetime(self, datetime64_value):\n",
    "        try:\n",
    "            h.data().loc[datetime64_value]\n",
    "            return True\n",
    "        except KeyError:\n",
    "            return False\n",
    "\n",
    "    def _get_nearist_index(self, before_or_after, datetime):\n",
    "        if before_or_after == 'before':\n",
    "            offset = -1\n",
    "        else:\n",
    "            offset = 0\n",
    "        index = max(h.data().index.searchsorted(datetime) + offset, 0)\n",
    "        return self.data().ix[self.data().index[index]]\n",
    "\n",
    "    ''' 引数の日時を含まない直前に存在する値を取得する '''        \n",
    "    def get_last_exist_datetime(self, datetime64_value):\n",
    "        return self._get_nearist_index('before', datetime64_value)\n",
    "        \n",
    "    ''' 引数の日時を含む直後に存在する値を取得する '''\n",
    "    def get_next_exist_datetime(self, datetime64_value):\n",
    "        return self._get_nearist_index('after', datetime64_value)\n",
    "    \n",
    "    ''' fromとtoの日時の差が閾値内にあるか否か '''\n",
    "    def is_datetime_diff_in_threshould(self, from_datetime, to_datetime, threshold_timedelta):\n",
    "        last_datetime = h.get_last_exist_datetime(from_datetime)\n",
    "        next_exist_datetime = h.get_next_exist_datetime(to_datetime)\n",
    "        delta = next_exist_datetime.name - last_datetime.name\n",
    "        return delta <= threshold_timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' ポジション '''\n",
    "class Position:\n",
    "    def __init__(self, buy_or_sell, price, amount):\n",
    "        self.price = price\n",
    "        self.amount = amount\n",
    "        self.buy_or_sell = buy_or_sell\n",
    "    \n",
    "    ''' 総利益を計算する '''\n",
    "    def calc_profit_by(self, now_price):\n",
    "        return self._calc_unit_profit_by(now_price) * self.amount\n",
    "\n",
    "    ''' 単位あたりの利益を計算する '''\n",
    "    def _calc_unit_profit_by(self, now_price):\n",
    "        if self.buy_or_sell == 'buy' or self.buy_or_sell == Action.BUY.value:\n",
    "            return now_price - self.price\n",
    "        else:\n",
    "            return self.price - now_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FXTrade(gym.core.Env):\n",
    "    AMOUNT_UNIT = 50000\n",
    "    THRESHOULD_TIME_DELTA = dt.timedelta(days=1)\n",
    "    \n",
    "    def __init__(self, initial_cash, spread, hist_data, seed_value=100000, logger=None):\n",
    "        self.hist_data = hist_data\n",
    "        self.initial_cash = initial_cash\n",
    "        self.cash = initial_cash\n",
    "        self.spread = spread\n",
    "        self._positions = []\n",
    "        self._max_date = self._datetime2float(hist_data.dates().max())\n",
    "        self._min_date = self._datetime2float(hist_data.dates().min())\n",
    "        self._seed = seed_value\n",
    "        self._logger = logger\n",
    "        np.random.seed(seed_value)\n",
    "\n",
    "        high = np.array([self._max_date, hist_data.max_value()])\n",
    "        low = np.array([self._min_date, hist_data.min_value()])\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "        self.observation_space = gym.spaces.Box(low = low, high = high) # DateFrame, Close prise\n",
    "        \n",
    "    def get_now_datetime_as(self, datetime_or_float):\n",
    "        if datetime_or_float == 'float':\n",
    "            return self._now_datetime\n",
    "        else:\n",
    "            dt = self._float2datetime(self._now_datetime)\n",
    "            return dt\n",
    "    \n",
    "    def _set_now_datetime(self, value):\n",
    "        if isinstance(value, float):\n",
    "            assert self._min_date <= value, value\n",
    "            assert value <= self._max_date, value\n",
    "            self._now_datetime = value\n",
    "            return value\n",
    "        else:\n",
    "            assert self._min_date <= self._datetime2float(value), '%f <= %f, %s' % (self._min_date, self._datetime2float(value), value)\n",
    "            assert self._datetime2float(value) <= self._max_date, '%f <= %f, %s' % (self._datetime2float(value), self._max_date, value)\n",
    "            float_val = self._datetime2float(value)\n",
    "            self._now_datetime = float_val\n",
    "            return float_val\n",
    "            \n",
    "    def setseed(self, seed_value):\n",
    "        self._seed = seed_value\n",
    "        print('Set seed value: %d' % self._seed)\n",
    "        return seed_value\n",
    "        \n",
    "    def _seed(self):\n",
    "        return self._seed\n",
    "    \n",
    "    def _datetime2float(self, datetime64_value):\n",
    "        try:\n",
    "            float_val = float(str(datetime64_value.astype('uint64'))[:10])\n",
    "            return float_val\n",
    "        except:\n",
    "            logger.error('_datetime2float except')\n",
    "            import pdb; pdb.set_trace()\n",
    "    \n",
    "    def _float2datetime(self, float_timestamp):\n",
    "        try:\n",
    "            datetime_val = np.datetime64(dt.datetime.utcfromtimestamp(float_timestamp))\n",
    "            return datetime_val\n",
    "        except:\n",
    "            logger.error('_float2datetime except')\n",
    "            import pdb; pdb.set_trace()\n",
    "    \n",
    "    ''' 総含み益を計算する '''\n",
    "    def _calc_total_unrealized_gain_by(self, now_close_value):\n",
    "        if not self._positions: # positions is empty\n",
    "            return 0\n",
    "        total_profit = 0\n",
    "        for position in self._positions:\n",
    "            total_profit += position.calc_profit_by(now_close_value)\n",
    "        return total_profit\n",
    "    \n",
    "    ''' 全ポジションを決済する '''\n",
    "    def _liquidate_all_positions_by(self, now_price):\n",
    "        total_profit = 0\n",
    "        buy_or_sell = self._positions[0].buy_or_sell\n",
    "        \n",
    "        for position in self._positions:\n",
    "            total_profit += position.calc_profit_by(now_price)\n",
    "        self._positions = []\n",
    "        self.cash += total_profit\n",
    "        return total_profit\n",
    "        \n",
    "    ''' 注文を出す '''\n",
    "    def _order(self, buy_or_sell, now_price, amount):\n",
    "        position = Position(buy_or_sell=buy_or_sell, price=now_price, amount=amount)\n",
    "        self._positions.append(position)\n",
    "        return position\n",
    "    \n",
    "    def _get_price_of(self, buy_or_sell, now_buy_price, now_sell_price):\n",
    "        if buy_or_sell == Action.BUY.value or buy_or_sell == Action.STAY.value:\n",
    "            return now_buy_price\n",
    "        elif buy_or_sell == Action.SELL.value:\n",
    "            return now_sell_price\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    ''' 各stepごとに呼ばれる\n",
    "        actionを受け取り、次のstateとreward、episodeが終了したかどうかを返すように実装 '''\n",
    "    def _step(self, action):\n",
    "        logger.debug('_step STARTED')\n",
    "        \n",
    "        # actionを受け取り、次のstateを決定\n",
    "        buy_or_sell_or_stay = action - 1\n",
    "        assert buy_or_sell_or_stay == -1 or \\\n",
    "            buy_or_sell_or_stay == 0 or \\\n",
    "            buy_or_sell_or_stay == 1, 'buy_or_sell_or_stay: %d' % buy_or_sell_or_stay\n",
    "        \n",
    "        dminute = 1 # minuteの増加量\n",
    "        # 今注目している日時を更新\n",
    "        logger.debug('今注目している日時を更新')\n",
    "        #import pdb; pdb.set_trace()\n",
    "        previous_datetime = self.get_now_datetime_as('datetime')\n",
    "        now_datetime = previous_datetime + np.timedelta64(dminute, 'm')\n",
    "                \n",
    "        logger.debug('before')\n",
    "        logger.debug(now_datetime)\n",
    "        logger.debug(self._now_datetime)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        self._set_now_datetime(now_datetime)\n",
    "        logger.debug('after')\n",
    "        logger.debug(now_datetime)\n",
    "        logger.debug(self._now_datetime)\n",
    "        # その時点における値群\n",
    "        if h.has_datetime(now_datetime):\n",
    "            modified_now_datetime = now_datetime\n",
    "        else:\n",
    "            modified_now_datetime = self.hist_data.get_last_exist_datetime(now_datetime).name\n",
    "        now_values = self.hist_data.data().loc[modified_now_datetime]\n",
    "        \n",
    "        now_buy_price = now_values['Close']\n",
    "        self._now_buy_price = now_buy_price\n",
    "        now_sell_price = now_buy_price - self.spread\n",
    "        \n",
    "        logger.debug(modified_now_datetime)\n",
    "        if pd.DatetimeIndex([modified_now_datetime]).hour[0] == 0 and\\\n",
    "            pd.DatetimeIndex([modified_now_datetime]).minute[0] == 0:\n",
    "            # 毎日00:00に表示\n",
    "            if now_datetime == modified_now_datetime:\n",
    "                logger.info('%s %f' % (now_datetime, now_buy_price))\n",
    "            else:\n",
    "                 logger.info('%s (mod: %s) %f' % (now_datetime, modified_now_datetime, now_buy_price))\n",
    "        \n",
    "        now_price = self._get_price_of(buy_or_sell_or_stay, now_buy_price, now_sell_price)\n",
    "        if self._positions: # position is not empty\n",
    "            if buy_or_sell_or_stay == Action.SELL.value:\n",
    "                if self._positions[0].buy_or_sell == Action.BUY.value:\n",
    "                    self._liquidate_all_positions_by(now_price)\n",
    "                else:\n",
    "                    self._order(buy_or_sell_or_stay, self.AMOUNT_UNIT, now_price)\n",
    "            elif buy_or_sell_or_stay == Action.BUY.value:\n",
    "                if self._positions[0].buy_or_sell == Action.SELL.value:\n",
    "                    self._liquidate_all_positions_by(now_price)\n",
    "                else:\n",
    "                    self._order(buy_or_sell_or_stay, self.AMOUNT_UNIT, now_price)\n",
    "        else: #position is empty\n",
    "            if buy_or_sell_or_stay != Action.STAY:\n",
    "                self._order(buy_or_sell_or_stay, self.AMOUNT_UNIT, now_price)\n",
    "            \n",
    "        \n",
    "        # 現在の総含み益を再計算\n",
    "        positions_buy_or_sell = None\n",
    "        if self._positions:\n",
    "            logger.debug('現在の総含み益を再計算')\n",
    "            positions_buy_or_sell = self._positions[0].buy_or_sell\n",
    "            logger.debug('buy_or_sell: %d' % positions_buy_or_sell)\n",
    "        else:\n",
    "            positions_buy_or_sell = Action.BUY.value\n",
    "        logger.debug('positions_buy_or_sell: %d', positions_buy_or_sell)\n",
    "        now_price_for_positions = self._get_price_of(positions_buy_or_sell, now_buy_price, now_sell_price)\n",
    "        self._total_unrealized_gain = self._calc_total_unrealized_gain_by(now_price_for_positions)\n",
    "\n",
    "        # 日付が学習データの最後と一致すれば終了\n",
    "        done = now_datetime == self.hist_data.dates()[-1]\n",
    "        if done:\n",
    "            print('now_datetime: %s' % now_datetime)\n",
    "            print('self.hist_data.dates()[-1]: %s' % self.hist_data.dates()[-1])\n",
    "\n",
    "\n",
    "        # 報酬は現金と総含み益\n",
    "        reward = self._total_unrealized_gain + self.cash\n",
    "        \n",
    "        # 次のstate、reward、終了したかどうか、追加情報の順に返す\n",
    "        # 追加情報は特にないので空dict\n",
    "        logger.debug('_step ENDED')\n",
    "        return np.array([self._now_datetime, self._now_buy_price]), reward, done, {}\n",
    "        \n",
    "    ''' 各episodeの開始時に呼ばれ、初期stateを返すように実装 '''\n",
    "    def _reset(self):\n",
    "        print('_reset START')\n",
    "        print('self._seed: %i' % self._seed)\n",
    "        initial_index = 0\n",
    "        \n",
    "        print('Start datetime: %s' % self.hist_data.dates()[initial_index])\n",
    "        now_buy_price = self.hist_data.data().ix[[initial_index], ['Close']].Close.iloc[0]\n",
    "        self._positions = []\n",
    "        print('_reset END')\n",
    "        next_state = [initial_index, now_buy_price]\n",
    "        import pdb; pdb.set_trace()\n",
    "        return np.array(next_state)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rl.callbacks\n",
    "class ModelSaver(rl.callbacks.TrainEpisodeLogger):\n",
    "    def __init__(self, filepath, monitor='loss', verbose=1, save_best_only=True, mode='min', save_weights_only=False):\n",
    "        if filepath is None:\n",
    "            raise ValueError('Give value to filepath. (Given: %s)' % filepath)\n",
    "        self.best_monitor_value = None\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.verbose = verbose\n",
    "        self.save_best_only = save_best_only\n",
    "        self.mode = mode\n",
    "        self.save_weights_only = save_weights_only\n",
    "        if mode not in ('min', 'max'):\n",
    "            raise ValueError(\"Give 'min' or 'max' to mode. (Given: %s)\" % mode)\n",
    "        self.mode = mode\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "    def on_episode_end(self, episode, logs):\n",
    "        print('========== Model Saver output ==============')\n",
    "        monitor_value = self._formatted_metrics(episode)[self.monitor]\n",
    "\n",
    "        #try:\n",
    "        print('%s value: %e' % (self.monitor, monitor_value))\n",
    "        values = {'episode': episode, self.monitor: monitor_value}\n",
    "        if not self.save_best_only:\n",
    "            values['previous_monitor'] = monitor_value\n",
    "            self._save_model(values)            \n",
    "        elif self.best_monitor_value is None or self._is_this_episode_improved(monitor_value):\n",
    "            previous_value = self.best_monitor_value\n",
    "            self.best_monitor_value = monitor_value\n",
    "            values['previous_monitor'] = previous_value\n",
    "            self._save_model(values)\n",
    "            print('%s %s value: %e' % (self.mode, self.monitor, self.best_monitor_value))\n",
    "        #except:\n",
    "        #    print('Not a float value given.')\n",
    "        print('========== /Model Saver output =============')\n",
    "        super().on_episode_end(episode, logs)\n",
    "\n",
    "    def _is_this_episode_improved(self, monitor_value):\n",
    "        if self.mode == 'min':\n",
    "            return monitor_value < self.best_monitor_value\n",
    "        else:\n",
    "            return monitor_value > self.best_monitor_value\n",
    "        \n",
    "    def _save_model(self, kwargs):\n",
    "        previous_monitor = kwargs['previous_monitor']\n",
    "        filepath = self.filepath.format_map(kwargs)\n",
    "        if self.verbose > 0:\n",
    "            print(\"Step %05d: model improved\\n  from %e\\n    to %e,\"\n",
    "                  ' saving model to %s'\n",
    "                  % (self.step, previous_monitor or 0.0,\n",
    "                     self.best_monitor_value or 0.0, filepath))\n",
    "        if self.save_weights_only:\n",
    "            self.model.save_weights(filepath + '.hdf5', overwrite=True)\n",
    "            print('Save weights to %s has done.' % filepath)\n",
    "        else:\n",
    "            self.model.model.save(filepath + '.h5', overwrite=True)\n",
    "            print('Save model to %s has done.' % filepath)\n",
    "\n",
    "    def _formatted_metrics(self, episode):\n",
    "        # Format all metrics.\n",
    "        metrics = np.array(self.metrics[episode])\n",
    "        metrics_variables = []\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('error')\n",
    "            for idx, name in enumerate(self.metrics_names):\n",
    "                try:\n",
    "                    value = np.nanmean(metrics[:, idx])\n",
    "                except Warning:\n",
    "                    if name == 'loss':\n",
    "                        value = float('inf')\n",
    "                    else:\n",
    "                        value = '--'\n",
    "                metrics_variables += [name, value]\n",
    "        return dict(itertools.zip_longest(*[iter(metrics_variables)] * 2, fillvalue=\"\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "''' 元のTensorBoardだと、value.item()で死ぬのでvalueに変更。変更点はここだけ。 '''\n",
    "class MyTensorBoard(keras.callbacks.TensorBoard):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.validation_data and self.histogram_freq:\n",
    "            if epoch % self.histogram_freq == 0:\n",
    "                # TODO: implement batched calls to sess.run\n",
    "                # (current call will likely go OOM on GPU)\n",
    "                if self.model.uses_learning_phase:\n",
    "                    cut_v_data = len(self.model.inputs)\n",
    "                    val_data = self.validation_data[:cut_v_data] + [0]\n",
    "                    tensors = self.model.inputs + [K.learning_phase()]\n",
    "                else:\n",
    "                    val_data = self.validation_data\n",
    "                    tensors = self.model.inputs\n",
    "                feed_dict = dict(zip(tensors, val_data))\n",
    "                result = self.sess.run([self.merged], feed_dict=feed_dict)\n",
    "                summary_str = result[0]\n",
    "                self.writer.add_summary(summary_str, epoch)\n",
    "\n",
    "        if self.embeddings_freq and self.embeddings_logs:\n",
    "            if epoch % self.embeddings_freq == 0:\n",
    "                for log in self.embeddings_logs:\n",
    "                    self.saver.save(self.sess, log, epoch)\n",
    "\n",
    "        for name, value in logs.items():\n",
    "            if name in ['batch', 'size']:\n",
    "                continue\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value # Modified from: value.item()\n",
    "            summary_value.tag = name\n",
    "            self.writer.add_summary(summary, epoch)\n",
    "        self.writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     8
    ],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "class DeepFX:\n",
    "    def __init__(self, env, mode, nb_steps=None,\n",
    "              log_directory='./logs', model_directory='./models',\n",
    "              model_filename='Keras-RL_DQN_FX_model_meanq{mean_q:e}_episode{episode:05d}',\n",
    "              prepared_model_filename=None,\n",
    "              weights_filename='Keras-RL_DQN_FX_weights.h5',):\n",
    "\n",
    "        self._log_directory = log_directory\n",
    "        self._model_directory = model_directory\n",
    "        self._model_filename = model_filename\n",
    "        self._prepared_model_filename = prepared_model_filename\n",
    "        self._weights_filename = weights_filename\n",
    "        self._load_model_path = self._relative_path(model_directory, prepared_model_filename) \n",
    "        self._save_model_path = self._relative_path(model_directory, model_filename)\n",
    "        self._env = env\n",
    "\n",
    "    def setup(self):\n",
    "        self._agent, self._model, self._memory, self._policy = self._initialize_agent()\n",
    "        self._agent.compile('adam')\n",
    "        print(self._model.summary())\n",
    "\n",
    "    def train(self, is_for_time_measurement=False, wipe_instance_variables_after=True):\n",
    "        self.setup()\n",
    "        self._callbacks = self._get_callbacks()\n",
    "        self._fit(self._agent, is_for_time_measurement, self._env, self._callbacks)\n",
    "        if wipe_instance_variables_after:\n",
    "            self._wipe_instance_variables()\n",
    "\n",
    "    def test(self, episodes, callbacks=[], wipe_instance_variables_after=True):\n",
    "        self.setup()\n",
    "        self._agent.test(self._env, nb_episodes=episodes, visualize=False, callbacks=callbacks)\n",
    "\n",
    "        %matplotlib inline\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        for obs in callbacks[0].rewards.values():\n",
    "            plt.plot([o for o in obs])\n",
    "        plt.xlabel(\"step\")\n",
    "        plt.ylabel(\"reward\")\n",
    "        if wipe_instance_variables_after:\n",
    "            self._wipe_instance_variables()\n",
    "        \n",
    "    def _wipe_instance_variables(self):\n",
    "         self._callbacks, self._agent, self._model, \\\n",
    "                self._memory, self._policy, self.env = [None] * 6\n",
    "        \n",
    "    def _relative_path(self, directory, filename):\n",
    "        if directory is None or filename is None:\n",
    "            return None\n",
    "        return os.path.join(directory, filename)\n",
    "\n",
    "    def _get_model(self, load_model_path, observation_space_shape, nb_actions):\n",
    "        if load_model_path is None:\n",
    "            # DQNのネットワーク定義\n",
    "            model = Sequential()\n",
    "            model.add(Flatten(input_shape=(1,) + observation_space_shape))\n",
    "        #    model.add(Dense(4))\n",
    "        #    model.add(Activation('relu'))\n",
    "        #    model.add(Dense(4))\n",
    "        #    model.add(Activation('relu'))\n",
    "            model.add(Dense(nb_actions))\n",
    "            model.add(Activation('relu'))\n",
    "        else:\n",
    "            model = keras.models.load_model(load_model_path)\n",
    "        return model\n",
    "\n",
    "    def _initialize_agent(self):\n",
    "        nb_actions = self._env.action_space.n\n",
    "        observation_space_shape = self._env.observation_space.shape\n",
    "        model = self._get_model(self._load_model_path, observation_space_shape, nb_actions)\n",
    "        \n",
    "        # experience replay用のmemory\n",
    "        memory = SequentialMemory(limit=500000, window_length=1)\n",
    "        # 行動方策はオーソドックスなepsilon-greedy。ほかに、各行動のQ値によって確率を決定するBoltzmannQPolicyが利用可能\n",
    "        policy = EpsGreedyQPolicy(eps=0.1) \n",
    "        dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=100,\n",
    "                       policy=policy)\n",
    "                       #target_model_update=1e-2, policy=policy)\n",
    "        #dqn.compile(Adam(lr=1e-3))\n",
    "        return (dqn, model, memory, policy)\n",
    "        \n",
    "    def _get_callbacks(self):\n",
    "        tensor_board_callback = MyTensorBoard(log_dir=self._log_directory, histogram_freq=1, embeddings_layer_names=True, write_graph=True)\n",
    "        model_saver_callback = ModelSaver(self._save_model_path, monitor='mean_q', mode='max')\n",
    "        callbacks = [tensor_board_callback, model_saver_callback]\n",
    "        return callbacks\n",
    "\n",
    "    def _fit(self, agent, is_for_time_measurement, env, callbacks=[]):\n",
    "        if is_for_time_measurement:\n",
    "            start = time.time()\n",
    "            print(DebugTools.now_str())\n",
    "            #minutes = 2591940/60 # 2591940secs = '2010-09-30 23:59:00' - '2010-09-01 00:00:00'\n",
    "            #minutes = (60 * 24 - 1) * 1# a day * 1\n",
    "            minutes = (60 * 24 - 1) * 10# a day * 10\n",
    "            #minutes = (60 * 24 - 1) * 2 # 2days\n",
    "            #minutes = (60 * 24 - 1) * 10 * 9999999 # 10days * 9999999 Epochs\n",
    "            #minutes = (60 * 24 - 1) * 30 * 9999999# 30days * 9999999 Epochs\n",
    "            history = agent.fit(env, nb_steps=minutes, visualize=False, verbose=2, nb_max_episode_steps=None, \\\n",
    "                             callbacks=callbacks)\n",
    "            elapsed_time = time.time() - start\n",
    "            print((\"elapsed_time:{0}\".format(elapsed_time)) + \"[sec]\")\n",
    "            print(DebugTools.now_str())\n",
    "        else:\n",
    "            history = agent.fit(env, nb_steps=50000, visualize=False, verbose=2, nb_max_episode_steps=None)\n",
    "        #学習の様子を描画したいときは、Envに_render()を実装して、visualize=True にします,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h = HistData('2010/9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EpisodeLogger(rl.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.observations = {}\n",
    "        self.rewards = {}\n",
    "        self.actions = {}\n",
    "\n",
    "    def on_episode_begin(self, episode, logs):\n",
    "        self.observations[episode] = []\n",
    "        self.rewards[episode] = []\n",
    "        self.actions[episode] = []\n",
    "\n",
    "    def on_step_end(self, step, logs):\n",
    "        episode = logs['episode']\n",
    "        self.observations[episode].append(logs['observation'])\n",
    "        self.rewards[episode].append(logs['reward'])\n",
    "        self.actions[episode].append(logs['action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FXTrade(1000000, 0.08, h, logger=logger)\n",
    "prepared_model_filename = None #'Keras-RL_DQN_FX_model_meanq1.440944e+06_episode00003.h5'\n",
    "dfx = DeepFX(env, 'test', prepared_model_filename=prepared_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/10/25 01:25:58\n",
      "Training for 14390 steps ...\n",
      "Training for 14390 steps ...\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2010-09-01T00:00:00.000000000\n",
      "_reset END\n",
      "> <ipython-input-39-480ff22af5a0>(199)_reset()\n",
      "-> return np.array(next_state)\n",
      "(Pdb) next_state\n",
      "[0, 84.180000000000007]\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-0271713a9261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mis_to_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_to_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_for_time_measurement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEpisodeLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-f178a8df5c68>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, is_for_time_measurement, wipe_instance_variables_after)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_for_time_measurement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwipe_instance_variables_after\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wipe_instance_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-f178a8df5c68>\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, agent, is_for_time_measurement, env, callbacks)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m#minutes = (60 * 24 - 1) * 10 * 9999999 # 10days * 9999999 Epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m#minutes = (60 * 24 - 1) * 30 * 9999999# 30days * 9999999 Epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminutes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_max_episode_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m                              \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"elapsed_time:{0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melapsed_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"[sec]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/rl/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, env, nb_steps, action_repetition, callbacks, verbose, visualize, nb_max_start_steps, start_step_policy, log_interval, nb_max_episode_steps)\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0;31m# Obtain the initial observation by resetting the environment.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                     \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-480ff22af5a0>\u001b[0m in \u001b[0;36m_reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minitial_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow_buy_price\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-480ff22af5a0>\u001b[0m in \u001b[0;36m_reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minitial_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow_buy_price\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "is_to_train = True\n",
    "if is_to_train:\n",
    "    dfx.train(is_for_time_measurement=True)\n",
    "else:\n",
    "    dfx.test(1, [EpisodeLogger()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
